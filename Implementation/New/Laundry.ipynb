{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "22XQq6pQ5NvFXRD0jVUiKv",
     "report_properties": {
      "rowId": "9oBF3rv3793YGxY3HcrZHr"
     },
     "type": "MD"
    }
   },
   "source": [
    "# Laundry System Simulation\n",
    "\n",
    "Starting from system description provided by the design team, implementation of the system take some design decision that was left open-ended in the design.\n",
    "\n",
    "Most changes are minor, and are of importance only to the implementation. Changes were made to ease and conform the system to SimPy framework.\n",
    "\n",
    "## System design\n",
    "\n",
    "### Queue design\n",
    "\n",
    "![The queue system design, redraw on my notebook](img/system_design.jpg)\n",
    "\n",
    "New assumption is that small laundry order can be performed by both small machine and large machine. Because small order now have choices, we prioritizes:\n",
    "\n",
    "- Best fit first - meaning that small order try small machine first\n",
    "- Available machine second - if no small machine is available, order can be processed by big machine\n",
    "\n",
    "Another new asumption is that order encountering a full queue will now be discarded (applied to all queue within the system).\n",
    "\n",
    "### Implementation detail\n",
    "\n",
    "We try to take a job/order approach to implement the system:\n",
    "\n",
    "- Each order record its own information, internal state, service history\n",
    "- Order will be guided through the system by a main controller. At each stage, job will be put into a queue for processing. Such staged processing is modeled like a state machine. Order keep their own state. Controller decides the next state and action that will change order's internal state.\n",
    "- At order completion, statistics can be extracted from job to update the culmulative statistics value.\n",
    "\n",
    "![Flowchart for order, showing processing various types of order can go through as they pass the system](img/job_centric_design_and_assumption.jpg)\n",
    "\n",
    "![Detailed state transition for order, conditions are omitted for clarity](img/job_state_change_detailed.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ntpt/Documents/Uni/PerformanceEval/BigAssignment/.env/lib/python3.11/site-packages (1.26.2)\r\n",
      "Requirement already satisfied: simpy in /home/ntpt/Documents/Uni/PerformanceEval/BigAssignment/.env/lib/python3.11/site-packages (4.1.1)\r\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'simpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mrnd\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msimpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'simpy'"
     ]
    }
   ],
   "source": [
    "!pip install numpy simpy\n",
    "\n",
    "from enum import Enum, auto\n",
    "import math\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import simpy as sp\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m MAX_SIMULATION_TIME \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# should use 3 log level (DEBUG, INFO, WARNING)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# DEBUG print the most; INFO print only finished job, WARNING should not print much\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m LOGGING_LEVEL \u001b[38;5;241m=\u001b[39m \u001b[43mlogging\u001b[49m\u001b[38;5;241m.\u001b[39mWARNING        \n\u001b[1;32m      6\u001b[0m LOG_FILE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m     \u001b[38;5;66;03m# log file name, left None if you don't want log file\u001b[39;00m\n\u001b[1;32m      7\u001b[0m PLOTTED \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m     \u001b[38;5;66;03m# no plotting for now\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logging' is not defined"
     ]
    }
   ],
   "source": [
    "# SIMULATION CONFIG\n",
    "MAX_SIMULATION_TIME = 1000\n",
    "# should use 3 log level (DEBUG, INFO, WARNING)\n",
    "# DEBUG print the most; INFO print only finished job, WARNING should not print much\n",
    "LOGGING_LEVEL = logging.WARNING        \n",
    "LOG_FILE = None     # log file name, left None if you don't want log file\n",
    "PLOTTED = False     # no plotting for now\n",
    "rnd.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a custom logger, output to console and file (if set)\n",
    "log = logging.getLogger(__name__)\n",
    "log.setLevel(LOGGING_LEVEL)\n",
    "# Create handlers for console (print)\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(LOGGING_LEVEL)\n",
    "console_handler.setFormatter(logging.Formatter())      # use default formatter\n",
    "log.addHandler(console_handler)\n",
    "if LOG_FILE is not None:\n",
    "    file_handler = logging.FileHandler(LOG_FILE)\n",
    "    file_handler.setLevel(LOGGING_LEVEL)\n",
    "    file_handler.setFormatter(logging.Formatter())      # use default formatter\n",
    "    log.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYSTEM PARAMETERS\n",
    "## SOURCE PARAMETERS\n",
    "SOURCE_LAMBDA = 30\n",
    "POPULATION = 5000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service parameters\n",
    "\n",
    "Each service in the system (checkin, wash, dry, iron/folding, checkout) will be represented as a Server object (queue included), we config each service below.\n",
    "\n",
    "All rate is measure per minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SERVICE CONFIG\n",
    "## CHECKIN\n",
    "CHECKIN_QUEUE_LENGTH = math.inf\n",
    "CHECKIN_SERVER_NUM = 1                  # 1 server only (arbitrary)\n",
    "CHECKIN_MEAN_SERVICE_RATE = 50          # is average mu of each server\n",
    "## BIGWASH\n",
    "BIGWASH_QUEUE_LENGTH = math.inf\n",
    "BIGWASH_SERVER_NUM = 4                  # 1 server only (arbitrary)\n",
    "BIGWASH_MEAN_SERVICE_RATE = 20          # is average mu of each server\n",
    "## SMALLWASH\n",
    "SMALLWASH_QUEUE_LENGTH = math.inf\n",
    "SMALLWASH_SERVER_NUM = 4                # 1 server only (arbitrary)\n",
    "SMALLWASH_MEAN_SERVICE_RATE = 20        # is average mu of each server\n",
    "## BIGDRY\n",
    "BIGDRY_QUEUE_LENGTH = math.inf\n",
    "BIGDRY_SERVER_NUM = 4                   # 1 server only (arbitrary)\n",
    "BIGDRY_MEAN_SERVICE_RATE = 20           # is average mu of each server\n",
    "## SMALLDRY\n",
    "SMALLDRY_QUEUE_LENGTH = math.inf\n",
    "SMALLDRY_SERVER_NUM = 4                 # 1 server only (arbitrary)\n",
    "SMALLDRY_MEAN_SERVICE_RATE = 20         # is average mu of each server\n",
    "## IRONFOLD\n",
    "IRONFOLD_QUEUE_LENGTH = math.inf\n",
    "IRONFOLD_SERVER_NUM = 4                 # 1 server only (arbitrary)\n",
    "IRONFOLD_MEAN_SERVICE_RATE = 30         # is average mu of each server\n",
    "## CHECKOUT\n",
    "CHECKOUT_QUEUE_LENGTH = math.inf\n",
    "CHECKOUT_SERVER_NUM = 1                 # 1 server only (arbitrary)\n",
    "CHECKOUT_MEAN_SERVICE_RATE = 50         # is average mu of each server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workload specification\n",
    "\n",
    "There are 3 types of order:                                              \n",
    "0. Only wash                                                         \n",
    "1. Only dry                                                         \n",
    "2. Wash & dry                                                                                                                           \n",
    "Each order will have a random exponentially distributed weight, config for such distribution is chosen below. We will classify them into weight class:                                                                   \n",
    "0. `[0kg, 10kg)`\n",
    "1. `[10kg, +inf kg)`                                                   \n",
    "Each order will have a expected waiting time, if the real waiting time is larger than this value, the order is considered completed late. For now this time will be x2 the total required time without queue blocking (using worst time for between big and small machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrderType(Enum):\n",
    "    WASH = 0\n",
    "    DRY = 1\n",
    "    WASHDRY = 2\n",
    " \n",
    "\n",
    "class OrderWeightClass(Enum):\n",
    "    SMALL = 0       # [0, 10kg)\n",
    "    BIG = 1         # [10, +inf kg)\n",
    "\n",
    "# WORKLOAD CONFIG\n",
    "## ORDER TYPES\n",
    "ORDER_TYPE_WEIGHT_FACTOR = [\n",
    "    1,              # for only wash\n",
    "    2,              # for only dry\n",
    "    1,              # for wash & dry\n",
    "]\n",
    "## ORDER WEIGHTS\n",
    "ORDER_WEIGHT_EXPONENTIAL_LAMBDA = 0.1    # chosen arbitrarily\n",
    "## ORDER EXPECTED WAITING TIME\n",
    "ORDER_EXPECTED_WAITING_TIME = [\n",
    "    2.0 * etime for etime in\n",
    "    [\n",
    "        # for wash, time includes checkin, wash, checkout\n",
    "        (1/CHECKOUT_MEAN_SERVICE_RATE) \n",
    "            + max(1/BIGWASH_MEAN_SERVICE_RATE, 1/SMALLWASH_MEAN_SERVICE_RATE)\n",
    "            + (1/CHECKOUT_MEAN_SERVICE_RATE),\n",
    "        # for dry, time includes checkin, dry, iron/fold, checkout\n",
    "        (1/CHECKOUT_MEAN_SERVICE_RATE) \n",
    "            + max(1/BIGDRY_MEAN_SERVICE_RATE, 1/SMALLDRY_MEAN_SERVICE_RATE)\n",
    "            + (1/IRONFOLD_MEAN_SERVICE_RATE)\n",
    "            + (1/CHECKOUT_MEAN_SERVICE_RATE),\n",
    "        # for wash+dry, time includes checkin, wash, dry, iron/fold, checkout\n",
    "        (1/CHECKOUT_MEAN_SERVICE_RATE) \n",
    "            + max(1/BIGWASH_MEAN_SERVICE_RATE, 1/SMALLWASH_MEAN_SERVICE_RATE)\n",
    "            + max(1/BIGDRY_MEAN_SERVICE_RATE, 1/SMALLDRY_MEAN_SERVICE_RATE)\n",
    "            + (1/IRONFOLD_MEAN_SERVICE_RATE)\n",
    "            + (1/CHECKOUT_MEAN_SERVICE_RATE),\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support data types definition\n",
    "\n",
    "This will be used later, including:\n",
    "\n",
    "- `ServiceType`: Used to differentiate between service provider (defined below)\n",
    "- `EventRecord`: Used to conveniently store service history of order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServiceType(Enum):\n",
    "    CI = auto()\n",
    "    WB = auto()\n",
    "    WS = auto()\n",
    "    DB = auto()\n",
    "    DS = auto()\n",
    "    IF = auto()\n",
    "    CO = auto()\n",
    "\n",
    "class EventRecord:\n",
    "    def __init__(self, type: ServiceType, queued_time = 0.0, start_time = 0.0, stop_time = 0.0) -> None:\n",
    "        self.type = type \n",
    "        self.queued_time = queued_time \n",
    "        self.start_time = start_time \n",
    "        self.stop_time = stop_time \n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f'({self.type}, {self.queued_time}, {self.start_time}, {self.stop_time})'\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `LaundryOrder` definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaundryOrder:\n",
    "    # various state for order, representing current status of order\n",
    "    class State(Enum):\n",
    "        START = auto()\n",
    "        CI = auto()\n",
    "        WB = auto()\n",
    "        WS = auto()\n",
    "        WB_DB = auto()\n",
    "        WS_DX = auto()\n",
    "        DB = auto()\n",
    "        DS = auto()\n",
    "        IF = auto()\n",
    "        CO = auto()\n",
    "        END = auto()\n",
    "    \n",
    "    def __init__(self, id=\"order_id\") -> None:\n",
    "        self.type = rnd.choices(list(OrderType), weights=ORDER_TYPE_WEIGHT_FACTOR)[0]\n",
    "        self.weight = rnd.expovariate(ORDER_WEIGHT_EXPONENTIAL_LAMBDA)\n",
    "        self.weight_class = OrderWeightClass.SMALL if self.weight < 10 else OrderWeightClass.BIG\n",
    "        self.expected_service_time = ORDER_EXPECTED_WAITING_TIME[self.type.value]\n",
    "        self.records = [ ]      # for storing EventRecord history\n",
    "        self.current_state = self.State.START\n",
    "        self.id = id\n",
    "        self.finished = False\n",
    "        self.finished_late = False\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f'{self.id}, {self.weight} Kg, {self.expected_service_time} m, {self.records}'\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ServiceProvider` definition\n",
    "\n",
    "This is the representation of a M/M/c queue.\n",
    "\n",
    "The class make use of SimPy resource type to implement limited server, while also implicitly implement queuing through the same resource type and SimPy's event queue.\n",
    "\n",
    "To put a order into queue, call `ServiceProvider.add_to_queue`. It will either schedule a SimPy process/event, returning `True` to signify successful queueing; or order queuing fails because queue is full, returning `False`.\n",
    "\n",
    "The class will also keep book of its own statistics. Which can be accessed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServiceProvider:\n",
    "    def __init__(self, env, type: ServiceType, server_num, service_rate, max_queue_len) -> None:\n",
    "        self.env = env\n",
    "        self.type = type\n",
    "        self.server_num = server_num\n",
    "        self.server_resource = sp.Resource(env, capacity=self.server_num)\n",
    "        self.service_rate = service_rate \n",
    "        self.max_queue_len = max_queue_len\n",
    "        # statistics\n",
    "        self.order_arrival = 0        # number of order try to queue\n",
    "        self.order_admitted = 0       # number of order successfully queued\n",
    "        self.order_waiting_time = 0 \n",
    "        self.order_service_time = 0\n",
    "        self.order_response_time = 0\n",
    "\n",
    "    def do_process(self, laundry_order):\n",
    "        self.order_admitted += 1\n",
    "        with self.server_resource.request() as res:\n",
    "            queued_time = env.now\n",
    "            yield res       # wait for resource to become available\n",
    "            start_time = env.now\n",
    "            service_time = rnd.expovariate(self.service_rate)\n",
    "            yield self.env.timeout(service_time)      # do process\n",
    "            stop_time = env.now\n",
    "            laundry_order.records.append(EventRecord(self.type, queued_time, start_time, stop_time))\n",
    "            self.order_waiting_time += start_time - queued_time\n",
    "            self.order_service_time += service_time\n",
    "            self.order_response_time += stop_time - queued_time\n",
    "\n",
    "    def add_to_queue(self, laundry_order):\n",
    "        self.order_arrival += 1\n",
    "        if len(self.server_resource.queue) < self.max_queue_len:\n",
    "            yield self.env.process(self.do_process(laundry_order))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_queue_full(self):\n",
    "        return len(self.server_resource.queue) >= self.max_queue_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `LaundrySystem` definition\n",
    "\n",
    "The controller, encompassing both order creation and all `ServiceProvider` within the system.\n",
    "\n",
    "State change logic is implemented in `LaundrySystem.process_laundry_order` and various similarly named helper functions.\n",
    "\n",
    "Take note of `LaundrySystem.collect_statistics`, which is run at completion of each order. Such a function is left unimplemented with the intention of letting testing team decide on what to do with orders' statistics, and customize its details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaundrySystem:\n",
    "    def __init__(self, env) -> None:\n",
    "        self.checkin = ServiceProvider(env, ServiceType.CI, CHECKIN_SERVER_NUM,\n",
    "                                       CHECKIN_MEAN_SERVICE_RATE, CHECKIN_QUEUE_LENGTH)\n",
    "        self.bigwash = ServiceProvider(env, ServiceType.WB, BIGWASH_SERVER_NUM,\n",
    "                                       BIGWASH_MEAN_SERVICE_RATE, BIGWASH_QUEUE_LENGTH)\n",
    "        self.smallwash = ServiceProvider(env, ServiceType.WS, SMALLWASH_SERVER_NUM,\n",
    "                                         SMALLWASH_MEAN_SERVICE_RATE, SMALLWASH_QUEUE_LENGTH)\n",
    "        self.bigdry = ServiceProvider(env, ServiceType.DB, BIGDRY_SERVER_NUM,\n",
    "                                      BIGDRY_MEAN_SERVICE_RATE, BIGDRY_QUEUE_LENGTH)\n",
    "        self.smalldry = ServiceProvider(env, ServiceType.DS, SMALLDRY_SERVER_NUM,\n",
    "                                        SMALLDRY_MEAN_SERVICE_RATE, SMALLDRY_QUEUE_LENGTH)\n",
    "        self.ironfold = ServiceProvider(env, ServiceType.IF, IRONFOLD_SERVER_NUM,\n",
    "                                        IRONFOLD_MEAN_SERVICE_RATE, IRONFOLD_QUEUE_LENGTH)\n",
    "        self.checkout = ServiceProvider(env, ServiceType.CO, CHECKOUT_SERVER_NUM,\n",
    "                                        CHECKOUT_MEAN_SERVICE_RATE, CHECKOUT_QUEUE_LENGTH)\n",
    "        self.env = env\n",
    "        self.order = 0\n",
    "        self.order_finished = 0\n",
    "        self.order_finished_late = 0\n",
    "        self.env.process(self.generate_laundry_order())\n",
    "\n",
    "    def generate_laundry_order(self):\n",
    "        for id in range(POPULATION):\n",
    "            self.order += 1\n",
    "            new_order = LaundryOrder(str(id))\n",
    "            env.process(self.process_laundry_order(new_order))\n",
    "            yield self.env.timeout(rnd.expovariate(SOURCE_LAMBDA))       # wait for interarrival time\n",
    "        \n",
    "    def process_laundry_order(self, laundry_order):\n",
    "        while True:\n",
    "            match laundry_order.current_state:\n",
    "                case LaundryOrder.State.START:\n",
    "                    log.debug(f'{laundry_order.id} start')\n",
    "                    laundry_order.current_state = LaundryOrder.State.CI\n",
    "                case LaundryOrder.State.CI:\n",
    "                    log.debug(f'{laundry_order.id} checkin start')\n",
    "                    yield self.env.process(self.process_laundry_order_checkin(laundry_order))\n",
    "                    log.debug(f'{laundry_order.id} checkin end')\n",
    "                case LaundryOrder.State.WB:\n",
    "                    log.debug(f'{laundry_order.id} big wash start')\n",
    "                    yield self.env.process(self.process_laundry_order_bigwash(laundry_order))\n",
    "                    log.debug(f'{laundry_order.id} big wash end')\n",
    "                case LaundryOrder.State.WS:\n",
    "                    log.debug(f'{laundry_order.id} small wash start')\n",
    "                    yield self.env.process(self.process_laundry_order_smallwash(laundry_order))\n",
    "                    log.debug(f'{laundry_order.id} small wash end')\n",
    "                case LaundryOrder.State.WB_DB:\n",
    "                    log.debug(f'{laundry_order.id} big wash big dry start')\n",
    "                    yield self.env.process(self.process_laundry_order_bigwash_bigdry(laundry_order))\n",
    "                    log.debug(f'{laundry_order.id} big wash big dry end')\n",
    "                case LaundryOrder.State.WS_DX:\n",
    "                    log.debug(f'{laundry_order.id} small wash x dry start')\n",
    "                    yield self.env.process(self.process_laundry_order_smallwash_xdry(laundry_order))\n",
    "                    log.debug(f'{laundry_order.id} small wash x dry end')\n",
    "                case LaundryOrder.State.DB:\n",
    "                    log.debug(f'{laundry_order.id} big dry start')\n",
    "                    yield self.env.process(self.process_laundry_order_bigdry(laundry_order))\n",
    "                    log.debug(f'{laundry_order.id} big dry end')\n",
    "                case LaundryOrder.State.DS:\n",
    "                    log.debug(f'{laundry_order.id} small dry start')\n",
    "                    yield self.env.process(self.process_laundry_order_smalldry(laundry_order))\n",
    "                    log.debug(f'{laundry_order.id} small dry end')\n",
    "                case LaundryOrder.State.IF:\n",
    "                    log.debug(f'{laundry_order.id} iron and fold start')\n",
    "                    yield self.env.process(self.process_laundry_order_ironfold(laundry_order))\n",
    "                    log.debug(f'{laundry_order.id} iron and fold end')\n",
    "                case LaundryOrder.State.CO:\n",
    "                    log.debug(f'{laundry_order.id} checkout start')\n",
    "                    yield self.env.process(self.process_laundry_order_checkout(laundry_order))\n",
    "                    log.debug(f'{laundry_order.id} checkout end')\n",
    "                case LaundryOrder.State.END:\n",
    "                    log.debug(f'{laundry_order.id} finish' if laundry_order.finished else\n",
    "                              f'{laundry_order.id} stop')\n",
    "                    if laundry_order.finished:\n",
    "                        log.info(laundry_order)     # on log level higher than DEBUG, only this run\n",
    "                    self.collect_statistics(laundry_order)\n",
    "                    break       # break out of further order processing \n",
    "                case _:\n",
    "                    raise Exception('Unknown laundry order state', laundry_order.current_state)\n",
    "\n",
    "    def process_laundry_order_checkin(self, laundry_order):\n",
    "        proc = yield self.env.process(self.checkin.add_to_queue(laundry_order))\n",
    "        if proc is False:        # adding order to queue failed\n",
    "            laundry_order.current_state = LaundryOrder.State.END\n",
    "        else:\n",
    "            match laundry_order.type, laundry_order.weight_class:\n",
    "                case OrderType.WASH, OrderWeightClass.BIG:\n",
    "                    laundry_order.current_state = LaundryOrder.State.WB\n",
    "                case OrderType.WASH, OrderWeightClass.SMALL:\n",
    "                    if not self.smallwash.is_queue_full():\n",
    "                        laundry_order.current_state = LaundryOrder.State.WS\n",
    "                    else:\n",
    "                        laundry_order.current_state = LaundryOrder.State.WB\n",
    "                case OrderType.DRY, OrderWeightClass.BIG:\n",
    "                    laundry_order.current_state = LaundryOrder.State.DB\n",
    "                case OrderType.DRY, OrderWeightClass.SMALL:\n",
    "                    if not self.smalldry.is_queue_full():\n",
    "                        laundry_order.current_state = LaundryOrder.State.DS\n",
    "                    else:\n",
    "                        laundry_order.current_state = LaundryOrder.State.DB\n",
    "                case OrderType.WASHDRY, OrderWeightClass.BIG:\n",
    "                    laundry_order.current_state = LaundryOrder.State.WB_DB\n",
    "                case OrderType.WASHDRY, OrderWeightClass.SMALL:\n",
    "                    if not self.smallwash.is_queue_full():\n",
    "                        laundry_order.current_state = LaundryOrder.State.WS_DX\n",
    "                    else:\n",
    "                        laundry_order.current_state = LaundryOrder.State.WB_DB\n",
    "                case _:\n",
    "                    raise Exception('Unknown laundry order type and weight class combination',\n",
    "                                    laundry_order.type, laundry_order.weight_class)\n",
    "\n",
    "    def process_laundry_order_bigwash(self, laundry_order):\n",
    "        assert laundry_order.current_state is LaundryOrder.State.WB\n",
    "        admitted = yield self.env.process(self.bigwash.add_to_queue(laundry_order))\n",
    "        if admitted is False:        # adding order to queue failed\n",
    "            laundry_order.current_state = LaundryOrder.State.END\n",
    "        else:\n",
    "            laundry_order.current_state = LaundryOrder.State.CO\n",
    "\n",
    "    def process_laundry_order_smallwash(self, laundry_order):\n",
    "        assert laundry_order.current_state is LaundryOrder.State.WS\n",
    "        admitted = yield self.env.process(self.smallwash.add_to_queue(laundry_order))\n",
    "        if admitted is False:        # adding order to queue failed\n",
    "            laundry_order.current_state = LaundryOrder.State.END\n",
    "        else:\n",
    "            laundry_order.current_state = LaundryOrder.State.CO\n",
    "\n",
    "    def process_laundry_order_bigwash_bigdry(self, laundry_order):\n",
    "        assert laundry_order.current_state is LaundryOrder.State.WB_DB\n",
    "        admitted = yield self.env.process(self.bigwash.add_to_queue(laundry_order))\n",
    "        if admitted is False:        # adding order to queue failed\n",
    "            laundry_order.current_state = LaundryOrder.State.END\n",
    "        else:\n",
    "            laundry_order.current_state = LaundryOrder.State.DB\n",
    "\n",
    "    def process_laundry_order_smallwash_xdry(self, laundry_order):\n",
    "        assert laundry_order.current_state is LaundryOrder.State.WS_DX\n",
    "        admitted = yield self.env.process(self.smallwash.add_to_queue(laundry_order))\n",
    "        if admitted is False:        # adding order to queue failed\n",
    "            laundry_order.current_state = LaundryOrder.State.END\n",
    "        else:\n",
    "            if not self.smalldry.is_queue_full():\n",
    "                laundry_order.current_state = LaundryOrder.State.DS\n",
    "            else:\n",
    "                laundry_order.current_state = LaundryOrder.State.DB\n",
    "\n",
    "    def process_laundry_order_bigdry(self, laundry_order):\n",
    "        assert laundry_order.current_state is LaundryOrder.State.DB\n",
    "        admitted = yield self.env.process(self.bigdry.add_to_queue(laundry_order))\n",
    "        if admitted is False:        # adding order to queue failed\n",
    "            laundry_order.current_state = LaundryOrder.State.END\n",
    "        else:\n",
    "            laundry_order.current_state = LaundryOrder.State.IF\n",
    "\n",
    "    def process_laundry_order_smalldry(self, laundry_order):\n",
    "        assert laundry_order.current_state is LaundryOrder.State.DS\n",
    "        admitted = yield self.env.process(self.smalldry.add_to_queue(laundry_order))\n",
    "        if admitted is False:        # adding order to queue failed\n",
    "            laundry_order.current_state = LaundryOrder.State.END\n",
    "        else:\n",
    "            laundry_order.current_state = LaundryOrder.State.IF\n",
    "\n",
    "    def process_laundry_order_ironfold(self, laundry_order):\n",
    "        assert laundry_order.current_state is LaundryOrder.State.IF\n",
    "        admitted = yield self.env.process(self.ironfold.add_to_queue(laundry_order))\n",
    "        if admitted is False:        # adding order to queue failed\n",
    "            laundry_order.current_state = LaundryOrder.State.END\n",
    "        else:\n",
    "            laundry_order.current_state = LaundryOrder.State.CO\n",
    "\n",
    "    def process_laundry_order_checkout(self, laundry_order):\n",
    "        assert laundry_order.current_state is LaundryOrder.State.CO\n",
    "        admitted = yield self.env.process(self.checkout.add_to_queue(laundry_order))\n",
    "        if admitted is False:        # adding order to queue failed\n",
    "            laundry_order.current_state = LaundryOrder.State.END\n",
    "        else:\n",
    "            laundry_order.current_state = LaundryOrder.State.END\n",
    "            laundry_order.finished = True\n",
    "            self.order_finished += 1\n",
    "\n",
    "            total_service_time = sum(\n",
    "                [record.stop_time - record.queued_time for record in laundry_order.records]\n",
    "            )\n",
    "            if total_service_time > laundry_order.expected_service_time:\n",
    "                self.order_finished_late += 1\n",
    "                laundry_order.finished_late = True\n",
    "\n",
    "    def collect_statistics(self, laundry_order):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# init the environment\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241m.\u001b[39mEnvironment()\n\u001b[1;32m      3\u001b[0m sys \u001b[38;5;241m=\u001b[39m LaundrySystem(env)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# print env time periodically for long running simulation\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sp' is not defined"
     ]
    }
   ],
   "source": [
    "# init the environment\n",
    "env = sp.Environment()\n",
    "sys = LaundrySystem(env)\n",
    "\n",
    "# print env time periodically for long running simulation\n",
    "def print_env_time(env):\n",
    "    while True:\n",
    "        print('Simulation time:', env.now)\n",
    "        yield env.timeout(200)\n",
    "env.process(print_env_time(env))\n",
    "\n",
    "env.run(until=MAX_SIMULATION_TIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print statistics after running simulation\u001b[39;00m\n\u001b[1;32m      2\u001b[0m queue_list \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 3\u001b[0m     (\u001b[43msys\u001b[49m\u001b[38;5;241m.\u001b[39mcheckin, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCheckin\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      4\u001b[0m     (sys\u001b[38;5;241m.\u001b[39mbigwash, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBig Wash\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      5\u001b[0m     (sys\u001b[38;5;241m.\u001b[39msmallwash, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSmall Wash\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      6\u001b[0m     (sys\u001b[38;5;241m.\u001b[39mbigdry, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBig Dry\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      7\u001b[0m     (sys\u001b[38;5;241m.\u001b[39msmalldry, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSmall Dry\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      8\u001b[0m     (sys\u001b[38;5;241m.\u001b[39mironfold, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIron & Fold\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      9\u001b[0m     (sys\u001b[38;5;241m.\u001b[39mcheckout, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCheckout\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     10\u001b[0m ]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m queue, queue_name \u001b[38;5;129;01min\u001b[39;00m queue_list:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(queue_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "# print statistics after running simulation\n",
    "queue_list = [\n",
    "    (sys.checkin, 'Checkin'),\n",
    "    (sys.bigwash, 'Big Wash'),\n",
    "    (sys.smallwash, 'Small Wash'),\n",
    "    (sys.bigdry, 'Big Dry'),\n",
    "    (sys.smalldry, 'Small Dry'),\n",
    "    (sys.ironfold, 'Iron & Fold'),\n",
    "    (sys.checkout, 'Checkout'),\n",
    "]\n",
    "\n",
    "for queue, queue_name in queue_list:\n",
    "    print(queue_name)\n",
    "    print('Arrivals'.rjust(20), ':', queue.order_arrival)\n",
    "    print('Admitted'.rjust(20), ':', queue.order_admitted)\n",
    "    print('Utilization'.rjust(20), ':', queue.order_service_time / (queue.server_num * env.now))\n",
    "    print('Mean waiting time'.rjust(20), ':', \n",
    "          0 if queue.order_admitted == 0 else queue.order_waiting_time / queue.order_admitted)\n",
    "    print('Mean service time'.rjust(20), ':', \n",
    "          0 if queue.order_admitted == 0 else queue.order_service_time / queue.order_admitted)\n",
    "    print('Mean response time'.rjust(20), ':', \n",
    "          0 if queue.order_admitted == 0 else queue.order_response_time / queue.order_admitted)\n",
    "    print('------------------------------------------------------------')\n",
    "\n",
    "# print stats of whole system\n",
    "print('System')\n",
    "print('Jobs finished'.rjust(20), ':', f'{sys.order_finished}/{sys.order}')\n",
    "print('Jobs finished late'.rjust(20), ':', f'{sys.order_finished_late}/{sys.order}')\n",
    "print('------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [
    {
     "name": "simpy",
     "source": "PIP",
     "version": "4.1.1"
    }
   ],
   "report_row_ids": [
    "9oBF3rv3793YGxY3HcrZHr",
    "0lGg1euhCQDmZTpcROzxyp",
    "s5uAhnAFFmel6xTk0t9asG",
    "WdI7MoFBAtbIhAXKuCpLvG",
    "37c5rwcpoWxfYeqHBHsgmL",
    "va8ikCRXHjwDMdlLkYA0VY",
    "AGYJruNPRonFpFkgJrEmm2",
    "JPE66WYE1KkmNW8iX5G7do",
    "bmQlJEFeGRuuynY4XrSw3n",
    "ZnT2CvL8aJGQNt9ZmQw3vz",
    "xT8XdoCQFbMbk39BCQfVRI",
    "UmHBqyo1Wz67pCKJMzKLGj",
    "dOgODQNxFELW1nwULBGqtP",
    "UEQ2xZ26Sg7TheNCv2fr2W",
    "wIU7oKbZoPpJbj7tnaqZRr",
    "RzI1gB6WqUdcbbDabq3Pn8",
    "QtVu0nxhMrq056BTeBf3bS",
    "107sD6cwfdneeDK3AzNLH7",
    "NLp6TjC9AjkXSw6OtRDZAY",
    "mfGn4za4JT4sQ9h5YAiJuM",
    "anXbgv6EcxE8GhPKdvyFg2",
    "W4rDz5ZLtb95UDd7wXMjbe",
    "O70tc8LKtxYEKmzfEDc5c2",
    "j1UJSYrznQda4zxCqJnCIN"
   ],
   "version": 3
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
